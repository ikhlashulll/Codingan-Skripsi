# -*- coding: utf-8 -*-
"""BINANCE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Aey0oXUWjR59fNXrhVmXafLDnHO4FAV-
"""

!pip install yfinance sru pandas_ta

import pandas as pd
import numpy as np
import yfinance as yf
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
from sru import SRU
import random
from sklearn.metrics import mean_squared_error, mean_absolute_error

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", device)

seed = 42
torch.manual_seed(seed)
torch.cuda.manual_seed(seed)
torch.cuda.manual_seed_all(seed)
np.random.seed(seed)
random.seed(seed)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

# =======================
# DATA LOADING
# =======================
def load_crypto(symbol: str, start: str, end: str) -> pd.DataFrame:
    df = yf.download(symbol, start=start, end=end)
    df = df[['Open', 'High', 'Low', 'Close', 'Volume']]
    df = df.add_prefix(symbol.replace("-USD", "") + "_")
    return df

df = load_crypto("BNB-USD", "2020-01-01", "2025-12-31")
print(df.tail(), df.shape)

# =======================
# SCALING & SEQUENCES
# =======================
scaler = MinMaxScaler()
scaled = scaler.fit_transform(df)
scaled_df = pd.DataFrame(scaled, columns=df.columns)
target = scaled_df["BNB_Close"].values

SEQ_LEN = 60
BATCH_SIZE = 32
LR = 1e-3

def create_sequences(data, target, seq_len):
    X, y = [], []
    for i in range(len(data) - seq_len):
        X.append(data[i:i+seq_len])
        y.append(target[i+seq_len])
    return np.array(X), np.array(y)

X, y = create_sequences(scaled_df.values, target, SEQ_LEN)

# Split data
train_size = int(0.7 * len(X))
val_size = int(0.15 * len(X))

X_train = X[:train_size]
y_train = y[:train_size]
X_val = X[train_size:train_size+val_size]
y_val = y[train_size:train_size+val_size]
X_test = X[train_size+val_size:]
y_test = y[train_size+val_size:]

# Convert to tensors
X_train_t = torch.tensor(X_train, dtype=torch.float32).to(device)
y_train_t = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1).to(device)
X_val_t = torch.tensor(X_val, dtype=torch.float32).to(device)
y_val_t = torch.tensor(y_val, dtype=torch.float32).unsqueeze(1).to(device)
X_test_t = torch.tensor(X_test, dtype=torch.float32).to(device)
y_test_t = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1).to(device)

train_dataset = TensorDataset(X_train_t, y_train_t)
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
y_test_np = y_test.reshape(-1,1)
dummy_cols = df.shape[1]-1
concat_actual = np.concatenate([y_test_np, np.zeros((y_test_np.shape[0], dummy_cols))], axis=1)
actual_inv = scaler.inverse_transform(concat_actual)[:,0]


class SRUPredictor(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout):
        super(SRUPredictor, self).__init__()
        self.sru = SRU(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers,
                       dropout=dropout, bidirectional=False)
        self.fc = nn.Linear(hidden_size, output_size)
    def forward(self, x):
        x = x.permute(1,0,2)
        out,_ = self.sru(x)
        return self.fc(out[-1])

class LSTMPredictor(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout):
        super(LSTMPredictor, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)
        self.fc = nn.Linear(hidden_size, output_size)
    def forward(self, x):
        out,_ = self.lstm(x)
        return self.fc(out[:, -1, :])

class GRUPredictor(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout):
        super(GRUPredictor, self).__init__()
        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)
        self.fc = nn.Linear(hidden_size, output_size)
    def forward(self, x):
        out,_ = self.gru(x)
        return self.fc(out[:, -1, :])

model_configs = {
    "SRU":  {"hidden_size": 32, "num_layers": 2, "dropout": 0.1, "num_epochs": 150},
    "LSTM": {"hidden_size": 128, "num_layers": 2, "dropout": 0.2, "num_epochs": 100},
    "GRU":  {"hidden_size": 128, "num_layers": 3, "dropout": 0.1, "num_epochs": 50},
}

input_size = X.shape[2]
output_size = 1

def train_model_return_preds(ModelClass, model_name):
    print(f"\n===== TRAINING {model_name} =====")
    cfg = model_configs[model_name]
    model = ModelClass(input_size, cfg["hidden_size"], cfg["num_layers"], output_size, cfg["dropout"]).to(device)
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=LR)

    for epoch in range(1, cfg["num_epochs"] + 1):
        model.train()
        epoch_loss = 0.0
        for xb, yb in train_loader:
            optimizer.zero_grad()
            preds = model(xb)
            preds = preds.view(yb.shape)
            loss = criterion(preds, yb)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item() * xb.size(0)
        epoch_loss /= len(train_loader.dataset)

        model.eval()
        with torch.no_grad():
            val_preds = model(X_val_t)
            val_preds = val_preds.view(y_val_t.shape)
            val_loss = criterion(val_preds, y_val_t).item()
        if epoch % 10 == 0 or epoch==1:
            print(f"Epoch {epoch}/{cfg['num_epochs']} - Train Loss: {epoch_loss:.6f} - Val Loss: {val_loss:.6f}")

    # EVALUATION
    model.eval()
    with torch.no_grad():
        preds_test = model(X_test_t).cpu().numpy().reshape(-1,1)

    dummy_cols = df.shape[1]-1
    concat_pred = np.concatenate([preds_test, np.zeros((preds_test.shape[0], dummy_cols))], axis=1)
    preds_inv = scaler.inverse_transform(concat_pred)[:,0]

    return preds_inv
preds_dict = {}
for model_name, ModelClass in zip(["SRU","LSTM","GRU"], [SRUPredictor,LSTMPredictor,GRUPredictor]):
    preds_dict[model_name] = train_model_return_preds(ModelClass, model_name)

from sklearn.metrics import mean_squared_error, mean_absolute_error

metrics_dict = {}

for model_name, preds in preds_dict.items():
    mse = mean_squared_error(actual_inv, preds)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(actual_inv, preds)
    mape = np.mean(np.abs((actual_inv - preds) / actual_inv)) * 100

    metrics_dict[model_name] = {
        "MSE": mse,
        "MAE": mae,
        "MAPE (%)": mape,
        "RMSE": rmse,


    }

print("\n===== MODEL PERFORMANCE =====")
for model_name, metrics in metrics_dict.items():
    print(f"{model_name}:")
    print(f"  MSE     : {metrics['MSE']:.4f}")

    print(f"  MAE     : {metrics['MAE']:.4f}")
    print(f"  MAPE (%) : {metrics['MAPE (%)']:.2f}")
    print(f"  RMSE    : {metrics['RMSE']:.4f}")

dates = df.index
dates_seq = dates[SEQ_LEN:]

train_size = int(len(dates_seq) * 0.8)

dates_train = dates_seq[:train_size]
dates_test  = dates_seq[train_size:]


plt.figure(figsize=(16,6))

plt.plot(
    dates_train,
    scaler.inverse_transform(
        np.hstack([
            y_train.reshape(-1,1),
            np.zeros((len(y_train), dummy_cols))
        ])
    )[:,0],
    label="Train Actual",
    linewidth=1.5,
    alpha=0.7
)

plt.plot(
    dates_val,
    scaler.inverse_transform(
        np.hstack([
            y_val.reshape(-1,1),
            np.zeros((len(y_val), dummy_cols))
        ])
    )[:,0],
    label="Validation Actual",
    linewidth=2,
    linestyle="--",
    color="orange"
)

plt.plot(
    dates_test,
    actual_inv,
    label="Test Actual",
    linewidth=2.5,
    color="black"
)

plt.plot(dates_test, preds_dict["SRU"], label="SRU Prediction", linewidth=2)
plt.plot(dates_test, preds_dict["LSTM"], label="LSTM Prediction", linewidth=2)
plt.plot(dates_test, preds_dict["GRU"], label="GRU Prediction", linewidth=2)

plt.axvline(dates_val[0], color="gray", linestyle="--", alpha=0.6)
plt.axvline(dates_test[0], color="gray", linestyle="--", alpha=0.6)

plt.text(dates_train[len(dates_train)//2], plt.ylim()[1]*0.95, "TRAIN", ha="center")
plt.text(dates_val[len(dates_val)//2], plt.ylim()[1]*0.95, "VALIDATION", ha="center")
plt.text(dates_test[len(dates_test)//2], plt.ylim()[1]*0.95, "TEST", ha="center")

plt.title(
    "SOL-USD Forecast (Split 70–15–15) dengan Model SRU, LSTM, dan GRU",
    fontsize=14,
    fontweight="bold"
)
plt.xlabel("Date")
plt.ylabel("Price (USD)")
plt.legend()
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()

"""========================================== analisis==========================================-

"""