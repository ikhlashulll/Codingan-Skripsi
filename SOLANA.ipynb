{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install yfinance sru pandas_ta\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sru import SRU\n",
        "import random\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6Do_PLhXxyP",
        "outputId": "9d871e2c-1fb2-4a4e-abad-a32a34ced3a0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.12/dist-packages (0.2.66)\n",
            "Requirement already satisfied: sru in /usr/local/lib/python3.12/dist-packages (2.6.0)\n",
            "Requirement already satisfied: pandas_ta in /usr/local/lib/python3.12/dist-packages (0.4.71b0)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.2.6)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.32.4)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.5.1)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.4.7)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.12/dist-packages (from yfinance) (3.19.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.13.5)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.14.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (5.29.5)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: torch>=1.5.1 in /usr/local/lib/python3.12/dist-packages (from sru) (2.9.0+cpu)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.12/dist-packages (from sru) (1.13.0)\n",
            "Requirement already satisfied: numba==0.61.2 in /usr/local/lib/python3.12/dist-packages (from pandas_ta) (0.61.2)\n",
            "Requirement already satisfied: tqdm>=4.67.1 in /usr/local/lib/python3.12/dist-packages (from pandas_ta) (4.67.1)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba==0.61.2->pandas_ta) (0.44.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.15.0)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2026.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (2.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.1->sru) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.1->sru) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.1->sru) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.1->sru) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.1->sru) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.1->sru) (2025.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.5.1->sru) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.5.1->sru) (3.0.3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sru/cuda_functional.py:23: UserWarning: Just-in-time loading and compiling the CUDA kernels of SRU was unsuccessful. Got the following error:\n",
            "CUDA_HOME environment variable is not set. Please set it to your CUDA install root.\n",
            "  warnings.warn(\"Just-in-time loading and compiling the CUDA kernels of SRU was unsuccessful. \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwEC69LAYmJN",
        "outputId": "eedbda6f-d8da-4729-8013-b6b53f5a10c3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_crypto(symbol: str, start: str, end: str) -> pd.DataFrame:\n",
        "    df = yf.download(symbol, start=start, end=end, auto_adjust=True)\n",
        "    if df.empty:\n",
        "        raise ValueError(f\"Data untuk {symbol} kosong. Pastikan ticker benar.\")\n",
        "    df = df[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
        "    df = df.add_prefix(symbol.replace(\"-USD\", \"\") + \"_\")\n",
        "    return df\n",
        "df = load_crypto(\"SOL-USD\", \"2020-01-01\", \"2025-12-31\")\n",
        "print(df.tail(), df.shape)\n"
      ],
      "metadata": {
        "id": "QPuPhsWDiEkE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10bbf234-2f78-4967-9cdb-9e956813f953"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/yfinance/scrapers/history.py:204: Pandas4Warning: Timestamp.utcnow is deprecated and will be removed in a future version. Use Timestamp.now('UTC') instead.\n",
            "  dt_now = pd.Timestamp.utcnow()\n",
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Price         SOL_Open    SOL_High     SOL_Low   SOL_Close  SOL_Volume\n",
            "Ticker     SOL_SOL-USD SOL_SOL-USD SOL_SOL-USD SOL_SOL-USD SOL_SOL-USD\n",
            "Date                                                                  \n",
            "2025-12-26  119.947372  124.929184  119.573166  122.195953  3779508002\n",
            "2025-12-27  122.196121  124.748161  121.860397  124.647713  1711358748\n",
            "2025-12-28  124.648415  125.217613  123.070587  125.199356  2003713687\n",
            "2025-12-29  125.198746  129.304413  122.428726  123.125229  4871847248\n",
            "2025-12-30  123.124489  126.190666  122.539001  124.931320  3096711898 (2091, 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vymlwr80EHSN"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaled = scaler.fit_transform(df)\n",
        "scaled_df = pd.DataFrame(scaled, columns=df.columns)\n",
        "target = scaled_df[\"SOL_Close\"].values\n",
        "\n",
        "SEQ_LEN = 60\n",
        "BATCH_SIZE = 32\n",
        "LR = 1e-3\n",
        "\n",
        "def create_sequences(data, target, seq_len):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_len):\n",
        "        X.append(data[i:i+seq_len])\n",
        "        y.append(target[i+seq_len])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X, y = create_sequences(scaled_df.values, target, SEQ_LEN)\n",
        "\n",
        "\n",
        "train_size = int(0.75 * len(X))\n",
        "val_size = int(0.15* len(X))\n",
        "\n",
        "X_train = X[:train_size]\n",
        "y_train = y[:train_size]\n",
        "X_val = X[train_size:train_size+val_size]\n",
        "y_val = y[train_size:train_size+val_size]\n",
        "X_test = X[train_size+val_size:]\n",
        "y_test = y[train_size+val_size:]\n",
        "\n",
        "\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1).to(device)\n",
        "X_val_t = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
        "y_val_t = torch.tensor(y_val, dtype=torch.float32).unsqueeze(1).to(device)\n",
        "X_test_t = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "y_test_t = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1).to(device)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "y_test_np = y_test.reshape(-1,1)\n",
        "dummy_cols = df.shape[1]-1\n",
        "concat_actual = np.concatenate([y_test_np, np.zeros((y_test_np.shape[0], dummy_cols))], axis=1)\n",
        "actual_inv = scaler.inverse_transform(concat_actual)[:,0]\n",
        "\n",
        "\n",
        "\n",
        "class SRUPredictor(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout):\n",
        "        super(SRUPredictor, self).__init__()\n",
        "        self.sru = SRU(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers,\n",
        "                       dropout=dropout, bidirectional=False)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        x = x.permute(1,0,2)\n",
        "        out,_ = self.sru(x)\n",
        "        return self.fc(out[-1])\n",
        "\n",
        "class LSTMPredictor(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout):\n",
        "        super(LSTMPredictor, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        out,_ = self.lstm(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "class GRUPredictor(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout):\n",
        "        super(GRUPredictor, self).__init__()\n",
        "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        out,_ = self.gru(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "\n",
        "model_configs = {\n",
        "    \"SRU\":  {\"hidden_size\": 64, \"num_layers\": 2, \"dropout\": 0.1, \"num_epochs\": 150},\n",
        "    \"LSTM\": {\"hidden_size\": 128, \"num_layers\": 2, \"dropout\": 0.2, \"num_epochs\": 100},\n",
        "    \"GRU\":  {\"hidden_size\": 64, \"num_layers\": 3, \"dropout\": 0.1, \"num_epochs\": 50}\n",
        "}\n",
        "\n",
        "input_size = X.shape[2]\n",
        "output_size = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_model_return_preds(ModelClass, model_name):\n",
        "    print(f\"\\n===== TRAINING {model_name} =====\")\n",
        "    cfg = model_configs[model_name]\n",
        "    model = ModelClass(input_size, cfg[\"hidden_size\"], cfg[\"num_layers\"], output_size, cfg[\"dropout\"]).to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "    for epoch in range(1, cfg[\"num_epochs\"] + 1):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "        for xb, yb in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(xb)\n",
        "            preds = preds.view(yb.shape)\n",
        "            loss = criterion(preds, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item() * xb.size(0)\n",
        "        epoch_loss /= len(train_loader.dataset)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_preds = model(X_val_t)\n",
        "            val_preds = val_preds.view(y_val_t.shape)\n",
        "            val_loss = criterion(val_preds, y_val_t).item()\n",
        "        if epoch % 10 == 0 or epoch==1:\n",
        "            print(f\"Epoch {epoch}/{cfg['num_epochs']} - Train Loss: {epoch_loss:.6f} - Val Loss: {val_loss:.6f}\")\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        preds_test = model(X_test_t).cpu().numpy().reshape(-1,1)\n",
        "\n",
        "    dummy_cols = df.shape[1]-1\n",
        "    concat_pred = np.concatenate([preds_test, np.zeros((preds_test.shape[0], dummy_cols))], axis=1)\n",
        "    preds_inv = scaler.inverse_transform(concat_pred)[:,0]\n",
        "\n",
        "    return preds_inv\n",
        "\n",
        "preds_dict = {}\n",
        "for model_name, ModelClass in zip([\"SRU\",\"LSTM\",\"GRU\"], [SRUPredictor,LSTMPredictor,GRUPredictor]):\n",
        "    preds_dict[model_name] = train_model_return_preds(ModelClass, model_name)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-EVzYHWF02_",
        "outputId": "4e97f794-9005-4269-dec9-52e134a0c3c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== TRAINING SRU =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sru/ops.py:162: UserWarning: Running SRU on CPU with grad_enabled=True. Are you sure?\n",
            "  warnings.warn(\"Running SRU on CPU with grad_enabled=True. Are you sure?\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150 - Train Loss: 0.026115 - Val Loss: 0.005474\n",
            "Epoch 10/150 - Train Loss: 0.000547 - Val Loss: 0.001072\n",
            "Epoch 20/150 - Train Loss: 0.000465 - Val Loss: 0.001397\n",
            "Epoch 30/150 - Train Loss: 0.000432 - Val Loss: 0.001086\n",
            "Epoch 40/150 - Train Loss: 0.000460 - Val Loss: 0.000930\n",
            "Epoch 50/150 - Train Loss: 0.000362 - Val Loss: 0.001301\n",
            "Epoch 60/150 - Train Loss: 0.000375 - Val Loss: 0.001203\n",
            "Epoch 70/150 - Train Loss: 0.000444 - Val Loss: 0.001715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "metrics_dict = {}\n",
        "\n",
        "for model_name, preds in preds_dict.items():\n",
        "    mse = mean_squared_error(actual_inv, preds)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(actual_inv, preds)\n",
        "    mape = np.mean(np.abs((actual_inv - preds) / actual_inv)) * 100\n",
        "\n",
        "    metrics_dict[model_name] = {\n",
        "        \"MSE\": mse,\n",
        "        \"MAE\": mae,\n",
        "        \"MAPE (%)\": mape,\n",
        "        \"RMSE\": rmse,\n",
        "\n",
        "\n",
        "    }\n",
        "\n",
        "print(\"\\n===== MODEL PERFORMANCE =====\")\n",
        "for model_name, metrics in metrics_dict.items():\n",
        "    print(f\"{model_name}:\")\n",
        "    print(f\"  MSE     : {metrics['MSE']:.4f}\")\n",
        "\n",
        "    print(f\"  MAE     : {metrics['MAE']:.4f}\")\n",
        "    print(f\"  MAPE (%) : {metrics['MAPE (%)']:.2f}\")\n",
        "    print(f\"  RMSE    : {metrics['RMSE']:.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z6sgCbAcEtrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(18,6))\n",
        "\n",
        "plt.plot(\n",
        "    train_dates,\n",
        "    actual_all_inv[:len(X_train)],\n",
        "    label=\"Train Actual\"\n",
        ")\n",
        "\n",
        "plt.plot(\n",
        "    val_dates,\n",
        "    actual_all_inv[len(X_train):len(X_train)+len(X_val)],\n",
        "    label=\"Validation Actual\"\n",
        ")\n",
        "\n",
        "plt.plot(\n",
        "    test_dates,\n",
        "    actual_all_inv[len(X_train)+len(X_val):],\n",
        "    label=\"Test Actual\"\n",
        ")\n",
        "\n",
        "plt.plot(test_dates, preds_dict[\"SRU\"], linestyle=\"--\", label=\"SRU Prediction\")\n",
        "plt.plot(test_dates, preds_dict[\"LSTM\"], linestyle=\"--\", label=\"LSTM Prediction\")\n",
        "plt.plot(test_dates, preds_dict[\"GRU\"], linestyle=\"--\", label=\"GRU Prediction\")\n",
        "\n",
        "plt.axvline(\n",
        "    x=val_dates[0],\n",
        "    linestyle=\":\",\n",
        "    linewidth=2,\n",
        "    label=\"Train–Validation Split\"\n",
        ")\n",
        "\n",
        "plt.axvline(\n",
        "    x=test_dates[0],\n",
        "    linestyle=\":\",\n",
        "    linewidth=2,\n",
        "    label=\"Validation–Test Split\"\n",
        ")\n",
        "\n",
        "plt.title(\"BNB Price Prediction (Train / Validation / Test)\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Price (USD)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ECTLDnXBUyQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zoom_days = 90\n",
        "\n",
        "dates_zoom = test_dates[-zoom_days:]\n",
        "actual_zoom = actual_all_inv[-zoom_days:]\n",
        "sru_zoom  = preds_dict[\"SRU\"][-zoom_days:]\n",
        "lstm_zoom = preds_dict[\"LSTM\"][-zoom_days:]\n",
        "gru_zoom  = preds_dict[\"GRU\"][-zoom_days:]\n",
        "\n",
        "plt.figure(figsize=(18,6))\n",
        "\n",
        "plt.plot(dates_zoom, actual_zoom, label=\"Actual\")\n",
        "plt.plot(dates_zoom, sru_zoom, label=\"SRU\")\n",
        "plt.plot(dates_zoom, lstm_zoom, label=\"LSTM\")\n",
        "plt.plot(dates_zoom, gru_zoom, label=\"GRU\")\n",
        "\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Price (USD)\")\n",
        "plt.title(\"BNB Price Prediction – Zoom 90 Days (Test Data)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iplFJzBjUy0d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}